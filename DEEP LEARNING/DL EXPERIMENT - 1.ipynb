{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning examples using Keras + Tensorflow<a href=\"#Deep-learning-examples-using-Keras-+-Tensorflow\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "## Build first network using Keras<a href=\"#Build-first-network-using-Keras\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[20\\]:\n",
    "\n",
    "    # Create simple network with Keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    import numpy\n",
    "\n",
    "    # load pima indians dataset\n",
    "    dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "    print(dataset.shape)\n",
    "    # split into input (X) and output (Y) variables\n",
    "    X = dataset[:,0:8]\n",
    "    Y = dataset[:,8]\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "\n",
    "    (768, 9)\n",
    "    (768, 8)\n",
    "    (768,)\n",
    "\n",
    "In \\[21\\]:\n",
    "\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "\n",
    "    # create first model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Adding 3 dense layers\n",
    "    model.add(Dense(12, input_dim=8, kernel_initializer='uniform'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X, Y, epochs=20, batch_size=10, verbose=2)\n",
    "\n",
    "    # Evaluate the model\n",
    "    scores = model.evaluate(X, Y)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n",
    "\n",
    "    Epoch 1/20\n",
    "    77/77 - 1s - loss: 5.3827 - accuracy: 0.6510 - 1s/epoch - 18ms/step\n",
    "    Epoch 2/20\n",
    "    77/77 - 0s - loss: 5.3827 - accuracy: 0.6510 - 94ms/epoch - 1ms/step\n",
    "    Epoch 3/20\n",
    "    77/77 - 0s - loss: 5.3827 - accuracy: 0.6510 - 101ms/epoch - 1ms/step\n",
    "    Epoch 4/20\n",
    "    77/77 - 0s - loss: 5.3827 - accuracy: 0.6510 - 82ms/epoch - 1ms/step\n",
    "    Epoch 5/20\n",
    "    77/77 - 0s - loss: 5.3827 - accuracy: 0.6510 - 101ms/epoch - 1ms/step\n",
    "    Epoch 6/20\n",
    "    77/77 - 0s - loss: 5.3827 - accuracy: 0.6510 - 99ms/epoch - 1ms/step\n",
    "    Epoch 7/20\n",
    "    77/77 - 0s - loss: 5.3827 - accuracy: 0.6510 - 101ms/epoch - 1ms/step\n",
    "    Epoch 8/20\n",
    "    77/77 - 0s - loss: 5.3827 - accuracy: 0.6510 - 101ms/epoch - 1ms/step\n",
    "    Epoch 9/20\n",
    "    77/77 - 0s - loss: 5.3827 - accuracy: 0.6510 - 83ms/epoch - 1ms/step\n",
    "    Epoch 10/20\n",
    "    77/77 - 0s - loss: 5.3827 - accuracy: 0.6510 - 99ms/epoch - 1ms/step\n",
    "    Epoch 11/20\n",
    "    77/77 - 0s - loss: 5.3827 - accuracy: 0.6510 - 100ms/epoch - 1ms/step\n",
    "    Epoch 12/20\n",
    "    77/77 - 0s - loss: 5.3827 - accuracy: 0.6510 - 100ms/epoch - 1ms/step\n",
    "    Epoch 13/20\n",
    "    77/77 - 0s - loss: 5.3827 - accuracy: 0.6510 - 88ms/epoch - 1ms/step\n",
    "    Epoch 14/20\n",
    "    77/77 - 0s - loss: 5.3827 - accuracy: 0.6510 - 96ms/epoch - 1ms/step\n",
    "    Epoch 15/20\n",
    "    77/77 - 0s - loss: 5.3827 - accuracy: 0.6510 - 101ms/epoch - 1ms/step\n",
    "    Epoch 16/20\n",
    "    77/77 - 0s - loss: 5.3827 - accuracy: 0.6510 - 82ms/epoch - 1ms/step\n",
    "    Epoch 17/20\n",
    "    77/77 - 0s - loss: 5.3827 - accuracy: 0.6510 - 99ms/epoch - 1ms/step\n",
    "    Epoch 18/20\n",
    "    77/77 - 0s - loss: 5.3827 - accuracy: 0.6510 - 87ms/epoch - 1ms/step\n",
    "    Epoch 19/20\n",
    "    77/77 - 0s - loss: 5.3827 - accuracy: 0.6510 - 86ms/epoch - 1ms/step\n",
    "    Epoch 20/20\n",
    "    77/77 - 0s - loss: 5.3827 - accuracy: 0.6510 - 100ms/epoch - 1ms/step\n",
    "    24/24 [==============================] - 0s 2ms/step - loss: 5.3827 - accuracy: 0.6510\n",
    "    accuracy: 65.10%\n",
    "\n",
    "In \\[22\\]:\n",
    "\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    import numpy as np\n",
    "\n",
    "    # Assuming you have X and Y defined\n",
    "    X = np.random.rand(100, 8)\n",
    "    Y = np.random.randint(2, size=(100, 1))\n",
    "\n",
    "    # Extending the first model with activation functions\n",
    "    model = Sequential()\n",
    "    # specifying activation functions\n",
    "    model.add(Dense(3, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "    # model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    model.fit(X, Y, epochs=20, batch_size=10, verbose=2)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X, Y)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "    Epoch 1/20\n",
    "    10/10 - 1s - loss: 0.6932 - accuracy: 0.4900 - 668ms/epoch - 67ms/step\n",
    "    Epoch 2/20\n",
    "    10/10 - 0s - loss: 0.6931 - accuracy: 0.5200 - 17ms/epoch - 2ms/step\n",
    "    Epoch 3/20\n",
    "    10/10 - 0s - loss: 0.6931 - accuracy: 0.5200 - 28ms/epoch - 3ms/step\n",
    "    Epoch 4/20\n",
    "    10/10 - 0s - loss: 0.6930 - accuracy: 0.5200 - 26ms/epoch - 3ms/step\n",
    "    Epoch 5/20\n",
    "    10/10 - 0s - loss: 0.6930 - accuracy: 0.5200 - 24ms/epoch - 2ms/step\n",
    "    Epoch 6/20\n",
    "    10/10 - 0s - loss: 0.6930 - accuracy: 0.5200 - 15ms/epoch - 1ms/step\n",
    "    Epoch 7/20\n",
    "    10/10 - 0s - loss: 0.6929 - accuracy: 0.5200 - 22ms/epoch - 2ms/step\n",
    "    Epoch 8/20\n",
    "    10/10 - 0s - loss: 0.6929 - accuracy: 0.5200 - 22ms/epoch - 2ms/step\n",
    "    Epoch 9/20\n",
    "    10/10 - 0s - loss: 0.6929 - accuracy: 0.5200 - 21ms/epoch - 2ms/step\n",
    "    Epoch 10/20\n",
    "    10/10 - 0s - loss: 0.6929 - accuracy: 0.5200 - 23ms/epoch - 2ms/step\n",
    "    Epoch 11/20\n",
    "    10/10 - 0s - loss: 0.6928 - accuracy: 0.5200 - 34ms/epoch - 3ms/step\n",
    "    Epoch 12/20\n",
    "    10/10 - 0s - loss: 0.6927 - accuracy: 0.5200 - 33ms/epoch - 3ms/step\n",
    "    Epoch 13/20\n",
    "    10/10 - 0s - loss: 0.6927 - accuracy: 0.5200 - 29ms/epoch - 3ms/step\n",
    "    Epoch 14/20\n",
    "    10/10 - 0s - loss: 0.6926 - accuracy: 0.5200 - 35ms/epoch - 3ms/step\n",
    "    Epoch 15/20\n",
    "    10/10 - 0s - loss: 0.6926 - accuracy: 0.5200 - 24ms/epoch - 2ms/step\n",
    "    Epoch 16/20\n",
    "    10/10 - 0s - loss: 0.6926 - accuracy: 0.5200 - 28ms/epoch - 3ms/step\n",
    "    Epoch 17/20\n",
    "    10/10 - 0s - loss: 0.6925 - accuracy: 0.5200 - 17ms/epoch - 2ms/step\n",
    "    Epoch 18/20\n",
    "    10/10 - 0s - loss: 0.6924 - accuracy: 0.5200 - 28ms/epoch - 3ms/step\n",
    "    Epoch 19/20\n",
    "    10/10 - 0s - loss: 0.6924 - accuracy: 0.5200 - 27ms/epoch - 3ms/step\n",
    "    Epoch 20/20\n",
    "    10/10 - 0s - loss: 0.6923 - accuracy: 0.5200 - 14ms/epoch - 1ms/step\n",
    "    4/4 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5200\n",
    "    accuracy: 52.00%\n",
    "\n",
    "In \\[23\\]:\n",
    "\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X, Y)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "    4/4 [==============================] - 0s 4ms/step - loss: 0.6922 - accuracy: 0.5200\n",
    "    accuracy: 52.00%\n",
    "\n",
    "In \\[24\\]:\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    Model: \"sequential_11\"\n",
    "    _________________________________________________________________\n",
    "     Layer (type)                Output Shape              Param #   \n",
    "    =================================================================\n",
    "     dense_18 (Dense)            (None, 3)                 27        \n",
    "                                                                     \n",
    "     dense_19 (Dense)            (None, 1)                 4         \n",
    "                                                                     \n",
    "    =================================================================\n",
    "    Total params: 31 (124.00 Byte)\n",
    "    Trainable params: 31 (124.00 Byte)\n",
    "    Non-trainable params: 0 (0.00 Byte)\n",
    "    _________________________________________________________________\n",
    "\n",
    "In \\[25\\]:\n",
    "\n",
    "    for layer in model.layers:\n",
    "        print(layer.name, layer.inbound_nodes, layer.outbound_nodes)\n",
    "\n",
    "    dense_18 [<keras.src.engine.node.Node object at 0x0000026C36A84350>] [<keras.src.engine.node.Node object at 0x0000026C341D4F10>]\n",
    "    dense_19 [<keras.src.engine.node.Node object at 0x0000026C341D4F10>] []\n",
    "\n",
    "In \\[26\\]:\n",
    "\n",
    "    model.get_weights()\n",
    "\n",
    "Out\\[26\\]:\n",
    "\n",
    "    [array([[ 0.00408516, -0.03824556,  0.05336154],\n",
    "            [-0.01365287, -0.02662184, -0.0863336 ],\n",
    "            [-0.00236633, -0.00805188,  0.02342406],\n",
    "            [-0.0376142 ,  0.07128999,  0.02236346],\n",
    "            [ 0.00530113,  0.06498241,  0.03108896],\n",
    "            [ 0.00153021,  0.07855786, -0.00715087],\n",
    "            [-0.04516111,  0.01733149, -0.08642501],\n",
    "            [-0.01349095,  0.09663353,  0.01225374]], dtype=float32),\n",
    "     array([0.        , 0.02472901, 0.03055072], dtype=float32),\n",
    "     array([[-0.04207002],\n",
    "            [-0.0471606 ],\n",
    "            [-0.09717872]], dtype=float32),\n",
    "     array([-0.02168271], dtype=float32)]\n",
    "\n",
    "In \\[27\\]:\n",
    "\n",
    "    # Multilayer Perceptron\n",
    "    from keras.utils import plot_model\n",
    "    # plot graph\n",
    "    plot_model(model, to_file='multilayer_perceptron_graph.png')\n",
    "\n",
    "    You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
    "\n",
    "In \\[28\\]:\n",
    "\n",
    "    # calculate predictions\n",
    "    predictions = model.predict(X)\n",
    "    # round predictions\n",
    "    rounded = [round(x[0]) for x in predictions]\n",
    "    print(predictions)\n",
    "    print(rounded)\n",
    "\n",
    "    4/4 [==============================] - 0s 4ms/step\n",
    "    [[0.4929139 ]\n",
    "     [0.49256784]\n",
    "     [0.49132445]\n",
    "     [0.49312127]\n",
    "     [0.4918405 ]\n",
    "     [0.4924666 ]\n",
    "     [0.49152392]\n",
    "     [0.49278897]\n",
    "     [0.4906243 ]\n",
    "     [0.49290502]\n",
    "     [0.4911851 ]\n",
    "     [0.49129277]\n",
    "     [0.4904201 ]\n",
    "     [0.49215528]\n",
    "     [0.49300703]\n",
    "     [0.4930487 ]\n",
    "     [0.49220452]\n",
    "     [0.4931847 ]\n",
    "     [0.49194697]\n",
    "     [0.4916489 ]\n",
    "     [0.49298796]\n",
    "     [0.49168053]\n",
    "     [0.49209145]\n",
    "     [0.49235302]\n",
    "     [0.49171907]\n",
    "     [0.49236298]\n",
    "     [0.4921858 ]\n",
    "     [0.49134725]\n",
    "     [0.49295077]\n",
    "     [0.4930056 ]\n",
    "     [0.49296683]\n",
    "     [0.49084595]\n",
    "     [0.4924072 ]\n",
    "     [0.49250337]\n",
    "     [0.49139842]\n",
    "     [0.49088252]\n",
    "     [0.49323717]\n",
    "     [0.49255052]\n",
    "     [0.49289742]\n",
    "     [0.4912865 ]\n",
    "     [0.4908141 ]\n",
    "     [0.49163476]\n",
    "     [0.4915635 ]\n",
    "     [0.49252492]\n",
    "     [0.49290055]\n",
    "     [0.4921511 ]\n",
    "     [0.49214286]\n",
    "     [0.49217358]\n",
    "     [0.49220276]\n",
    "     [0.49330065]\n",
    "     [0.4914404 ]\n",
    "     [0.49356264]\n",
    "     [0.4917385 ]\n",
    "     [0.49291065]\n",
    "     [0.49153262]\n",
    "     [0.49185982]\n",
    "     [0.49325958]\n",
    "     [0.49257794]\n",
    "     [0.49166065]\n",
    "     [0.49193636]\n",
    "     [0.49134287]\n",
    "     [0.49248675]\n",
    "     [0.49194586]\n",
    "     [0.49346983]\n",
    "     [0.4924448 ]\n",
    "     [0.49320865]\n",
    "     [0.49258116]\n",
    "     [0.48969114]\n",
    "     [0.4903111 ]\n",
    "     [0.49198994]\n",
    "     [0.49325818]\n",
    "     [0.49235588]\n",
    "     [0.4910813 ]\n",
    "     [0.49128672]\n",
    "     [0.49293697]\n",
    "     [0.49375835]\n",
    "     [0.4916388 ]\n",
    "     [0.49272802]\n",
    "     [0.49202588]\n",
    "     [0.49271235]\n",
    "     [0.4937761 ]\n",
    "     [0.49130383]\n",
    "     [0.493002  ]\n",
    "     [0.49023455]\n",
    "     [0.49301904]\n",
    "     [0.49375597]\n",
    "     [0.49261567]\n",
    "     [0.49230275]\n",
    "     [0.49211094]\n",
    "     [0.49104366]\n",
    "     [0.49396294]\n",
    "     [0.4923011 ]\n",
    "     [0.4912987 ]\n",
    "     [0.49163583]\n",
    "     [0.49054557]\n",
    "     [0.4929655 ]\n",
    "     [0.49200803]\n",
    "     [0.49238533]\n",
    "     [0.49261132]\n",
    "     [0.49303722]]\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# Second Keras example<a href=\"#Second-Keras-example\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[29\\]:\n",
    "\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    import numpy as np\n",
    "\n",
    "    # Assuming you have X and Y defined\n",
    "    X = np.random.rand(100, 8)\n",
    "    Y = np.random.randint(2, size=(100, 1))\n",
    "\n",
    "    # Extending the first model with activation functions\n",
    "    model = Sequential()\n",
    "    # specifying activation functions\n",
    "    model.add(Dense(3, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "    # model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    model.fit(X, Y, epochs=20, batch_size=10, verbose=2)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X, Y)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "    Epoch 1/20\n",
    "    10/10 - 1s - loss: 0.6932 - accuracy: 0.4700 - 626ms/epoch - 63ms/step\n",
    "    Epoch 2/20\n",
    "    10/10 - 0s - loss: 0.6932 - accuracy: 0.4300 - 25ms/epoch - 2ms/step\n",
    "    Epoch 3/20\n",
    "    10/10 - 0s - loss: 0.6932 - accuracy: 0.5300 - 21ms/epoch - 2ms/step\n",
    "    Epoch 4/20\n",
    "    10/10 - 0s - loss: 0.6931 - accuracy: 0.5500 - 19ms/epoch - 2ms/step\n",
    "    Epoch 5/20\n",
    "    10/10 - 0s - loss: 0.6931 - accuracy: 0.5300 - 25ms/epoch - 3ms/step\n",
    "    Epoch 6/20\n",
    "    10/10 - 0s - loss: 0.6931 - accuracy: 0.5500 - 28ms/epoch - 3ms/step\n",
    "    Epoch 7/20\n",
    "    10/10 - 0s - loss: 0.6931 - accuracy: 0.5400 - 14ms/epoch - 1ms/step\n",
    "    Epoch 8/20\n",
    "    10/10 - 0s - loss: 0.6930 - accuracy: 0.5300 - 19ms/epoch - 2ms/step\n",
    "    Epoch 9/20\n",
    "    10/10 - 0s - loss: 0.6929 - accuracy: 0.5400 - 15ms/epoch - 2ms/step\n",
    "    Epoch 10/20\n",
    "    10/10 - 0s - loss: 0.6929 - accuracy: 0.5500 - 22ms/epoch - 2ms/step\n",
    "    Epoch 11/20\n",
    "    10/10 - 0s - loss: 0.6929 - accuracy: 0.5600 - 30ms/epoch - 3ms/step\n",
    "    Epoch 12/20\n",
    "    10/10 - 0s - loss: 0.6929 - accuracy: 0.6000 - 17ms/epoch - 2ms/step\n",
    "    Epoch 13/20\n",
    "    10/10 - 0s - loss: 0.6928 - accuracy: 0.5800 - 26ms/epoch - 3ms/step\n",
    "    Epoch 14/20\n",
    "    10/10 - 0s - loss: 0.6928 - accuracy: 0.5600 - 22ms/epoch - 2ms/step\n",
    "    Epoch 15/20\n",
    "    10/10 - 0s - loss: 0.6927 - accuracy: 0.5700 - 28ms/epoch - 3ms/step\n",
    "    Epoch 16/20\n",
    "    10/10 - 0s - loss: 0.6926 - accuracy: 0.5600 - 38ms/epoch - 4ms/step\n",
    "    Epoch 17/20\n",
    "    10/10 - 0s - loss: 0.6926 - accuracy: 0.5800 - 22ms/epoch - 2ms/step\n",
    "    Epoch 18/20\n",
    "    10/10 - 0s - loss: 0.6925 - accuracy: 0.6100 - 22ms/epoch - 2ms/step\n",
    "    Epoch 19/20\n",
    "    10/10 - 0s - loss: 0.6924 - accuracy: 0.6000 - 21ms/epoch - 2ms/step\n",
    "    Epoch 20/20\n",
    "    10/10 - 0s - loss: 0.6924 - accuracy: 0.5700 - 15ms/epoch - 1ms/step\n",
    "    4/4 [==============================] - 0s 7ms/step - loss: 0.6923 - accuracy: 0.6200\n",
    "    accuracy: 62.00%\n",
    "\n",
    "In \\[32\\]:\n",
    "\n",
    "    max_words = 1000  # For example, if you're using a vocabulary size of 1000 words\n",
    "\n",
    "In \\[33\\]:\n",
    "\n",
    "    max_words\n",
    "\n",
    "Out\\[33\\]:\n",
    "\n",
    "    1000\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "     \n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "     \n",
    "\n",
    "In \\[ \\]:"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
